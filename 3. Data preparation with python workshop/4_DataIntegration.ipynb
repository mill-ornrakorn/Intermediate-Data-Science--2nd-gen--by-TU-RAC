{"cells":[{"cell_type":"markdown","metadata":{"id":"ceuP_6TTn2D_"},"source":["## Hands-On Data Preprocessing in Python\n","Learn how to effectively prepare data for successful data analytics\n","    \n","## Data Fusion and Data Integration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8eRhTO9n2EB"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"5YjR3KDsAv0m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmJ8IGF4n2EC"},"source":["## Data Fusion versus Data Integration\n","**Data integration** is a process in which heterogeneous data is retrieved and combined as an incorporated form and structure. Data integration allows different data types (such as data sets, documents and tables) to be merged by users, organizations and applications, for use as personal or business processes and/or functions.\n","<br></br>\n","**Data fusion** is the process of getting data from multiple sources in order to build more sophisticated models and understand more about a project. It often means getting combined data on a single subject and combining it for central analysis.\n","<br></br>\n","\n","<center><img src=\"https://drive.google.com/uc?id=1DDSaTJ0sGTDwAqBYEzOXR4d6ITZTXvyV\" width=\"500\"/></center>\n","\n","\n","**Data integration example**: Imagine that a company would like to analyze its effectiveness in how it advertises. The company needs to come up with two columns of data – the total sales per customer and the total amount of advertisement expenditure per customer. As the sales department and marketing department keep and manage their databases, each department will be tasked with creating a list of customers with the relevant information. Once they've done that, they need to connect the data of each customer from the two sources. This connection can be made by relying on the existence of real customers, so no assumptions need to be made. No changes need to be made to connect this data.\n","<br></br>\n","**Data fusion example**: Imagine a technology-empowered farmer who would like to see the influence of irrigation (water dispersion) on yield. The farmer has data regarding both the amount of water its revolving water stations have dispensed and the amount of harvest from each point in the farm. Each stationary water station has a sensor and calculates and records the amount of water that is dispensed. Also, each time the blade in the combine harvester moves, the machine calculates and record the amount of harvest and the location.\n","<br></br>\n","In this example, there is no clear connection between the sources of data. In the previous example, the clear connection was the definition of data objects - customers. So we need to make assumptions and change the data so that a connection is possible."]},{"cell_type":"markdown","source":["## Frequent Challenges of Data Fusion and Integration\n","**Challenge 1 –  entity identification**\n","\n","The challenge is that the data objects in all the data sources are the same real-world entities with the same definitions of data objects, but they are not easy to connect due to the unique identifiers in the data sources.\n","\n","For instance, in the data integration example section, the sales department and the marketing department did not use a central customer unique identifier for all their customers. Due to this lack of data management, when they want to integrate the data, they will have to figure out which customer is which in the data sources.\n","<br></br>\n","\n","**Challenge 2 –  unwise data collection**\n","\n","This data integration challenge happens, as its name suggests, due to unwise data collection. For instance, instead of using a centralized database, the data of different data objects is stored in multiple files.\n","<br></br>\n","\n","**Challenge 3 –  index mismatched formatting**\n","<img src=\"https://drive.google.com/uc?id=1LvBE81XfzA9BUqJFFOAepnwPfQM9XELM\" width=\"700\"/>\n","\n","**Challenge 4 –  aggregation mismatch**\n","\n","This challenge occurs when integrating data sources by adding attributes. When integrating time series data sources whose time intervals are not identical, this challenge arises.\n","\n","<img src=\"https://drive.google.com/uc?id=1-XCAVYTohQaw9YbBG1hrrqxj1eL2OjEy\" width=\"500\"/>\n","<br></br>\n","\n","**Challenge 5 –  duplicate data objects**\n","\n","This challenge occurs when we're integrating data sources by <font color='blue'>adding data objects</font>. When the sources contain data objects that are also in the other sources, when the data sources are integrated, there will be duplicates of the same data objects in the integrated dataset.\n","\n","For example, imagine a hospital that provides different kinds of healthcare services. For a project, we need to gather the socioeconomic data of all of the patients in the hospital. The imaginary hospital does not have a centralized database, so all of the departments are tasked with returning a dataset containing all the patients they have provided services for. After integrating all of the datasets from different departments, you should expect that there are multiple rows for the patients that had to receive care from different departments in the hospital.\n","<br></br>\n","\n","**Challenge 6 – data redundancy**\n","\n","Unlike the previous challenge, this challenge may be faced when you're integrating data sources by <font color='blue'>adding attributes</font>. After data integration, some of the attributes may be redundant. This redundancy could be shallow as there are two attributes with different titles but the same data. Or, it could be deeper. In deeper data redundancy cases, the redundant attribute does not have the same title, nor is its data the same as one of the other attributes, but the values of the redundant attribute can be derived from the other attributes.\n"],"metadata":{"id":"feoyXZ5HxDjN"}},{"cell_type":"markdown","source":["### Example 1 (Challenges 3 & 4)\n","---\n","In this example, we have two sources of data. The first was retrieved from the local electricity provider that holds the electricity consumption (**Electricity Data 2016_2017.csv**), while the other was retrieved from the local weather station and includes temperature data (**Temperature 2016.csv**). We want to see if we can come up with a visualization that can answer if and how the amount of electricity consumption is affected by the weather."],"metadata":{"id":"o8tyi42lxVso"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDfOYgu2n2EC"},"outputs":[],"source":["electric_df = pd.read_csv('Electricity Data 2016_2017.csv')\n","temp_df = pd.read_csv('Temperature 2016.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_JXMAnVn2EC"},"outputs":[],"source":["electric_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoWDiM5Dn2ED"},"outputs":[],"source":["temp_df"]},{"cell_type":"markdown","source":["- The data object definition of electric_df is the electric consumption in 15 minutes, but the data object definition of temp_df is the temperature every 1 hour. This shows that we have to face the aggregation mismatch challenge of data integration (**Challenge 4**).\n","- temp_df only contains the data for 2016, while electric_df contains the data for 2016 and some parts of 2017.\n","- Neither temp_df nor electric_df has indexes that can be used to connect the data objects across the two DataFrames. This shows that we will also have to face the challenge of index mismatched formatting (**Challenge 3**).\n","<br></br>\n","\n","**1.1 Remove the 2017 data objects from electric_df**"],"metadata":{"id":"IvUR__hHBULv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bXydyC6n2EE"},"outputs":[],"source":["BM = electric_df.Date.str.contains('2017')\n","dropping_index = electric_df[BM].index\n","electric_df.drop(index = dropping_index,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Czs2-mKCn2EE"},"outputs":[],"source":["electric_df"]},{"cell_type":"markdown","source":["**1.2 Add a new column titled <font color='blue'>Hour</font> to electric_df from the Time attribute**"],"metadata":{"id":"8yJCakeuB5Uy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqW0VoSln2EE"},"outputs":[],"source":["electric_df['Hour'] = electric_df.Time.apply(lambda v: '{}:00'.format(v.split(':')[0]))\n","electric_df"]},{"cell_type":"markdown","source":["**1.3 Create a new data structure whose definition of the data object is hourly electricity consumption**\n","\n","The following code uses the <font color='blue'>.groupby()</font> function to create *integrate_sr*. The Pandas *integrate_sr* series is a stopgap data structure that will be used for integration in the later steps.\n","\n","> One good question to ask here is this, why are we using the <font color='blue'>.sum()</font> aggregate function instead of .<font color='blue'>mean()</font>? The reason is the nature of the data. The electricity consumption of an hour is the summation of the electricity consumption of its half-hour pieces."],"metadata":{"id":"s9KdFmcNDehJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WU0KBBoRn2EE"},"outputs":[],"source":["integrate_sr = electric_df.groupby(['Date','Hour']).Consumption.sum()\n","integrate_sr"]},{"cell_type":"markdown","source":["**1.4 Add the <font color='blue'>Date</font> and <font color='blue'>Hour</font> columns to temp_df from Timestamp**"],"metadata":{"id":"-hLJ8pLSEaZt"}},{"cell_type":"code","source":["temp_df"],"metadata":{"id":"y4eOIUtLEscR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WTYh70Cn2EF"},"outputs":[],"source":["def unpackTimestamp(r):\n","  ts = r.Timestamp\n","  date,time = ts.split('T')\n","  hour = time.split(':')[0]\n","  year,month,day = date.split('-')\n","\n","  r['Hour'] = '{}:00'.format(int(hour))\n","  r['Date'] = '{}/{}/{}'.format(int(month),int(day),year)\n","  return(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QoSw5UI8n2EF"},"outputs":[],"source":["temp_df = temp_df.apply(unpackTimestamp,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lG4Mc3eBn2EF"},"outputs":[],"source":["temp_df = temp_df.set_index(['Date','Hour']).drop(columns=['Timestamp'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M15x39m6n2EF"},"outputs":[],"source":["temp_df"]},{"cell_type":"markdown","source":["**1.5 Ready to use <font color='blue'>.join()</font> to integrate the two sources**"],"metadata":{"id":"CVB489ZwF0CY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"88UwoA2qn2EG"},"outputs":[],"source":["integrate_df = temp_df.join(integrate_sr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfhYEKCIn2EG"},"outputs":[],"source":["integrate_df"]},{"cell_type":"markdown","source":["**1.6 Reset the index of integrate_df**\n","\n","We no longer need the index for integration purposes, nor do we need those values for visualization purposes."],"metadata":{"id":"kVB7TyS9NPMy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTytl2z7n2EG"},"outputs":[],"source":["integrate_df.reset_index(inplace=True)"]},{"cell_type":"code","source":["integrate_df"],"metadata":{"id":"7ORPHf9QNwi0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**1.7 Create a line plot of the whole year's electricity consumption**\n","\n","- The code created the <font color='blue'>days</font> list, which contains all the unique dates from integrate_df. By and large, the preceding code is a loop through the days list, and for each unique day, the line plot of electricity consumption is drawn and added to the days before and after. The color of each day's line plot is determined by that day's temperature average, that is, <font color='blue'>temp.mean()</font>.\n","\n","- The colors in the visualization are created based on the **RGB** color codes. RGB stands for Red, Green, and Blue. All colors can be created by using a combination of these three colors. You can specify the amount of each color you'd like and Matplotlib will produce that color for you. These colors can take values from 0 to 1 for Matplotlib.\n","\n","- A <font color='blue'>Boolean Mask (BM)</font> and <font color='blue'>plt.xticks()</font> are used to include the 28th of each month on the x axis so that we don't have a cluttered x axis."],"metadata":{"id":"U7jv740FNd5A"}},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"XMrfQhlzn2EG"},"outputs":[],"source":["days = integrate_df.Date.unique()\n","\n","max_temp, min_temp = integrate_df.temp.max(), integrate_df.temp.min()\n","green = 0.1\n","\n","plt.figure(figsize=(20,5))\n","\n","for d in days:\n","  BM = integrate_df.Date == d\n","  wdf = integrate_df[BM]\n","\n","  average_temp = wdf.temp.mean()\n","  red = (average_temp - min_temp)/ (max_temp - min_temp)\n","  blue = 1-red\n","  clr = [red,green,blue]\n","  plt.plot(wdf.index,wdf.Consumption,c = clr)\n","\n","BM = (integrate_df.Hour =='0:00') & (integrate_df.Date.str.contains('/28/'))\n","plt.xticks(integrate_df[BM].index,integrate_df[BM].Date,rotation=90)\n","plt.grid()\n","plt.margins(y=0,x=0)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ewY7MIUAn2EG"},"source":["### Example 2 (Challenge 2 & 3)\n","---\n","The data includes the sensor performance readings of six taekwondo athletes, who have varying levels of experience and expertise. We would like to see if the athlete's- gender, age, weight, and experience influence the level of impact they can create when they perform the following techniques:\n","- Roundhouse/Round Kick (R)\n","- Back Kick (B)\n","- Cut Kick (C)\n","- Punch (P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9DM1VYgn2EG"},"outputs":[],"source":["athlete_df = pd.read_csv('Table1.csv')\n","athlete_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPFsQhi2n2EG"},"outputs":[],"source":["unknown_df = pd.read_csv('Taekwondo.csv')\n","unknown_df"]},{"cell_type":"markdown","source":["**2.1 Create an empty pandas DataFrame called\n","<font color='blue'>performance_df**</font>\n","\n","This dataset has been designed so that both *athlete_df* and\n","*unknown_df* can be integrated into it."],"metadata":{"id":"rDEnc1ZbV83d"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQ_rntpBn2EH"},"outputs":[],"source":["designed_columns = ['Participant_id','Gender','Age','Weight','Experience','Technique_id','Trial_number','Average_read']\n","n_rows = len(unknown_df.columns)-1\n","performance_df = pd.DataFrame(index=range(n_rows),columns=designed_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K98hBH3In2EH"},"outputs":[],"source":["performance_df"]},{"cell_type":"markdown","source":["**2.2 Perform some level I data cleaning for <font color='blue'>athlete_df</font>**"],"metadata":{"id":"RXMYxHRjW8j3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDxwcgE2n2EH"},"outputs":[],"source":["athlete_df.set_index('Participant ID',inplace=True)\n","athlete_df.columns = ['Sex', 'Age', 'Weight', 'Experience', 'Belt']\n","athlete_df"]},{"cell_type":"markdown","source":["**2.3 Create and run the loop that will fill up\n","<font color='blue'>performance_df</font>**\n","\n","Because the dataset has been collected unwisely, we cannot use simple functions such as <font color='blue'>.join()</font> for data integration here. Instead, we need to use a loop to go through the many records of unknown_df and athlete_df and fill out performance_df row by row and, at times, cell by cell."],"metadata":{"id":"xfLkHmDcXTzN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsvSNxRHn2EH"},"outputs":[],"source":["techniques = ['R','B','C','P']\n","index = 0\n","for col in unknown_df.columns:\n","    if(col[0] in techniques):\n","        performance_df.loc[index,'Technique_id'] = col[0]\n","        performance_df.loc[index,'Trial_number'] = unknown_df[col][1]\n","\n","        P_id = unknown_df[col][0]\n","        performance_df.loc[index,'Participant_id'] = P_id\n","        performance_df.loc[index,'Gender'] = athlete_df.loc[P_id].Sex\n","        performance_df.loc[index,'Age'] = athlete_df.loc[P_id].Age\n","        performance_df.loc[index,'Weight'] = athlete_df.loc[P_id].Weight\n","        performance_df.loc[index,'Experience'] = athlete_df.loc[P_id].Experience\n","\n","        BM = unknown_df[col][2:].isna()\n","        performance_df.loc[index,'Average_read'] = unknown_df[col][2:][~BM].astype(int).mean()\n","        index +=1"]},{"cell_type":"code","source":["performance_df"],"metadata":{"id":"llK_r4boTQVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2.4 Bring our attention to the data analytic goals**"],"metadata":{"id":"wgNmYBGEYtrO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCg3honfn2EH"},"outputs":[],"source":["select_attributes = ['Gender','Age','Experience','Weight']\n","\n","for i,att in enumerate(select_attributes):\n","  plt.subplot(2,2,i+1)\n","  sns.boxplot(data=performance_df, y='Average_read', x=att)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","source":["In the preceding diagram, we can see meaningful relationships between Average_read and Gender, Age, Experience, and Weight. In a nutshell, these attributes can change the impact of the techniques that are performed by the athletes. For example, we can see that as the **experience** of an athlete increases, the impact of the techniques that are performed by the athlete increases.\n","<br></br>\n","We can also see a surprising trend: the impact of the techniques that are performed by **female** athletes is significantly higher than the impact of male athletes. After seeing this surprising trend, let's look back at athlete_df. We will realize that there is <font color='red'>only one female</font> athlete in the data, so we cannot count on this visualized trend."],"metadata":{"id":"ZbCuYNKqYy4-"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}